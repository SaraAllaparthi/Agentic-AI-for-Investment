# -*- coding: utf-8 -*-
"""Agentic AI for Investments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aelmfQ4HtR8eHvRNNIeWkkJIk3h8Bl9n
"""

pip install streamlit

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning Libraries
from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# For optional neural network section
# comment out if not needed
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.preprocessing import MinMaxScaler

# Set a Streamlit-wide config for plots

def main():
    """
    Main function to run the Streamlit app.
    """

    # 1) App Title and Description
    st.title("Predictive Asset Price Modeling")
    st.markdown("""
    This app fetches historical stock data from **Yahoo! Finance**, engineers features,
    and trains multiple models (Linear, Ridge, Random Forest, optionally a Neural Network)
    to predict the next day's closing price.
    """)

    # 2) Sidebar Inputs for User
    st.sidebar.header("Model Configuration")

    # Select Ticker
    ticker = st.sidebar.text_input("Enter a stock ticker (e.g., AAPL, GOOG):", "AAPL")

    # Select Start and End Date
    start_date = st.sidebar.date_input("Start Date", value=pd.to_datetime("2015-01-01"))
    end_date = st.sidebar.date_input("End Date", value=pd.to_datetime("2024-11-27"))

    # Button to fetch data
    if st.sidebar.button("Fetch and Process Data"):
        with st.spinner("Downloading data..."):
            data = download_data(ticker, start_date, end_date)
        st.success("Data Downloaded Successfully!")

        if data.empty:
            st.warning("No data found for the given date range. Please adjust.")
            return

        # 3) Show Data Preview
        st.subheader("Data Preview")
        st.dataframe(data.head(5))

        # 4) Feature Engineering + Model Training
        data_prepared = feature_engineering(data)
        st.subheader("Training Models")
        results, plot_df = train_and_evaluate_models(data_prepared, ticker)

        # 5) Display Evaluation Results
        st.subheader("Model Evaluation Metrics (Test Set)")
        st.write(results)

        # 6) Visualize Predictions
        st.subheader(f"{ticker} Closing Price Predictions vs. Actual")
        plt.figure(figsize=(14,7))
        plt.plot(plot_df.index, plot_df['Actual Price'], label='Actual Price', color='blue')
        if 'Linear Regression Prediction' in plot_df:
            plt.plot(plot_df.index, plot_df['Linear Regression Prediction'], label='Linear Regression', color='red')
        if 'Ridge Regression Prediction' in plot_df:
            plt.plot(plot_df.index, plot_df['Ridge Regression Prediction'], label='Ridge Regression', color='orange')
        if 'Random Forest Prediction' in plot_df:
            plt.plot(plot_df.index, plot_df['Random Forest Prediction'], label='Random Forest', color='green')
        if 'Neural Network Prediction' in plot_df:
            plt.plot(plot_df.index, plot_df['Neural Network Prediction'], label='Neural Network', color='purple')
        plt.title(f"{ticker} - Prediction Comparison")
        plt.xlabel("Date")
        plt.ylabel("Price (USD)")
        plt.legend()
        plt.xticks(rotation=45)
        st.pyplot()

@st.cache_data
def download_data(ticker, start_date, end_date):
    """
    Fetch data from yfinance.
    """
    data = yf.download(ticker, start=start_date, end=end_date)
    return data

def feature_engineering(data):
    """
    Perform feature engineering (e.g. rename columns, add technical indicators).
    Returns a DataFrame ready for modeling.
    """
    # Flatten MultiIndex columns if present
    if isinstance(data.columns, pd.MultiIndex):
        data.columns = ['_'.join(col).strip() for col in data.columns]

    # Basic cleanup
    data.dropna(inplace=True)

    # Create Technical Indicators
    data['MA10'] = data['Close'].rolling(window=10).mean()
    data['MA50'] = data['Close'].rolling(window=50).mean()

    # RSI
    delta = data['Close'].diff()
    up = delta.clip(lower=0)
    down = -1 * delta.clip(upper=0)
    ema_up = up.ewm(com=13, adjust=False).mean()
    ema_down = down.ewm(com=13, adjust=False).mean()
    rs = ema_up / ema_down
    data['RSI'] = 100 - (100/(1+rs))

    # MACD
    ema_12 = data['Close'].ewm(span=12, adjust=False).mean()
    ema_26 = data['Close'].ewm(span=26, adjust=False).mean()
    data['MACD'] = ema_12 - ema_26

    # Drop rows with NaN
    data.dropna(inplace=True)

    # Define target as next day's close
    data['Target'] = data['Close'].shift(-1)
    data.dropna(inplace=True)

    # Shift features by 1 day to avoid look-ahead bias
    shifted_features = ['Close', 'MA10', 'MA50', 'RSI', 'MACD']
    for sf in shifted_features:
        data[sf] = data[sf].shift(1)
    data.dropna(inplace=True)

    # We can remove a highly correlated feature, e.g. MA50, but let's keep it for now
    return data

def train_and_evaluate_models(data, ticker):
    """
    Train Linear Regression, Ridge, and Random Forest.
    Return a dictionary of MSE & R2 metrics and a DataFrame for plotting.
    """
    # Features
    features = ['Close', 'MA10', 'MA50', 'RSI', 'MACD']
    # (Optionally remove highly correlated features, e.g. 'MA50')
    # features = ['Close', 'MA10', 'RSI', 'MACD']

    X = data[features]
    y = data['Target']

    # Train-Test Split (time-based)
    train_size = int(len(X) * 0.8)
    X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]
    y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]

    # TimeSeriesSplit for cross-validation
    tscv = TimeSeriesSplit(n_splits=5)

    results = {}
    plot_df = pd.DataFrame(index=X_test.index)
    plot_df['Actual Price'] = y_test

    # 1) Linear Regression
    lr_model = LinearRegression() # Fixed: Removed the extra indentation
    lr_model.fit(X_train, y_train)
    lr_predictions = lr_model.predict(X_test)
    lr_mse = mean_squared

     # 2) Ridge Regression
    alpha_range = {'alpha': [0.1, 1.0, 10.0, 100.0]}
    ridge = Ridge()
    grid_search_ridge = GridSearchCV(estimator=ridge, param_grid=alpha_range, cv=tscv,
                                     scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search_ridge.fit(X_train, y_train)
    best_ridge = grid_search_ridge.best_estimator_
    ridge_predictions = best_ridge.predict(X_test)
    ridge_mse = mean_squared_error(y_test, ridge_predictions)
    ridge_r2 = r2_score(y_test, ridge_predictions)
    results['Ridge Regression'] = {'MSE': ridge_mse, 'R2': ridge_r2}
    plot_df['Ridge Regression Prediction'] = ridge_predictions

    # 3) Random Forest
    param_dist = {
        'n_estimators': [100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2],
        'max_features': ['sqrt', None],
        'bootstrap': [True, False]
    }
    rf = RandomForestRegressor(random_state=42)
    grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_dist, cv=tscv,
                                  n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)
    grid_search_rf.fit(X_train, y_train)
    best_rf = grid_search_rf.best_estimator_
    rf_predictions = best_rf.predict(X_test)
    rf_mse = mean_squared_error(y_test, rf_predictions)
    rf_r2 = r2_score(y_test, rf_predictions)
    results['Random Forest'] = {'MSE': rf_mse, 'R2': rf_r2}
    plot_df['Random Forest Prediction'] = rf_predictions

    # (Optional) 4) Neural Network Example
    # Comment out if not used
    try:
        # Scale features
        scaler_X = MinMaxScaler()
        scaler_y = MinMaxScaler()

        X_scaled = scaler_X.fit_transform(X)
        y_scaled = scaler_y.fit_transform(y.values.reshape(-1,1))

        X_train_scaled = X_scaled[:train_size]
        X_test_scaled  = X_scaled[train_size:]
        y_train_scaled = y_scaled[:train_size]
        y_test_scaled  = y_scaled[train_size:]

        model = Sequential()
        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))
        model.add(Dropout(0.2))
        model.add(Dense(64, activation='relu'))
        model.add(Dense(1))

        model.compile(optimizer='adam', loss='mean_squared_error')
        model.fit(X_train_scaled, y_train_scaled, epochs=5, batch_size=32, verbose=0)  # short training for demo

        nn_predictions_scaled = model.predict(X_test_scaled)
        nn_predictions = scaler_y.inverse_transform(nn_predictions_scaled)

        nn_mse = mean_squared_error(y_test, nn_predictions)
        nn_r2 = r2_score(y_test, nn_predictions)
        results['Neural Network'] = {'MSE': nn_mse, 'R2': nn_r2}
        plot_df['Neural Network Prediction'] = nn_predictions
    except:
        pass

    return results, plot_df

if __name__ == "__main__":
    main()